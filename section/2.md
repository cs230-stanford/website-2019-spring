---
# Page settings
layout: default
keywords:
comments: false

# Hero section
title: Section 2
description: A walkthrough of first steps for implementing a project - finding a codebase and running a baseline.

# Micro navigation
micro_nav: true

---

# Introduction

In this section, we’re going to try out some first steps for implementing a project: finding a good codebase, as well as running a baseline model. A baseline model is the first, simple model used to start a project. This simple model serves as a starting point in terms of accuracy, and provides a comparison with future, more complex models. 

In general, if there are existing implementations of your task, try to reproduce results by running their code. If there is no implementation of your task, you could find a solved proxy task, and plug in your own dataset. For instance, if you want to build a fish breed classifier, you can find open source code for a cat breed classifier, and plug in your fish breed dataset with the right labels.

If you need a refresher on the terminal or git, take a look at this [tutorial](https://d1b10bmlvqabco.cloudfront.net/attach/jd9nm7v2drf4bz/j7v7aqkb9194qv/jgic5sc45imn/CS230GithubTutorial.pdf).


# Case Study: Style Transfer

{% include image.html description="Le musée du Louvre in Impressionist style from Ng, Katanforoosh & Bensouda." link="https://www.deeplearning.ai/deep-learning-specialization/" image="section/2/styletransfer.png" caption="true"%}

Let’s say that you’re working on a project called “Improving Neural Style Transfer”.


## Finding a Good GitHub Repository

A great starting point for implementing your project idea is finding a high-quality GitHub repository. Here’s a general guide:

(1) **How many stars does the repository have?** In general, the number of stars is a good indicator of the quality of the content and number of users. 

(2) **What is the license for the repository?**  Repositories with MIT, Apache, GNU GPL, and BSD licenses are open source. This usually means that you can use the code as you would like with credits to the author(s) (in some cases, you may need to use the same license in your own codebase.).

(3) **Is the README clear and detailed?** **Are results reported?** **Is it possible to quickly set up the repository locally?** Good repositories provide detailed instructions in the README to install and run the code, and provide numerical and qualitative results. This is really important: a repository with vague or outdated setup instructions can be extremely hard to use.

(4) **Does the repository have links to download compatible datasets, and ideally, pretrained model weights?** Connecting a dataset to a codebase can be difficult. Some repositories have instructions for how to download and use a compatible dataset. In addition, many repositories provide pretrained model weights (the parameter values for a network after it has been trained on a standard dataset), so that you don’t need to replicate that work.

(5) **Is the code written in your preferred deep learning framework? (Tensorflow, Pytorch, Keras, etc.)**

(6) **How is the code’s quality and readability?** Check that the code is commented and the repository folders are well-structured.

(7) **Does the repository provide references?** You can usually find references at the bottom of the README. These provide context for the implementation.


## Hands On

  * **The GitHub repository 
[neural-style](https://github.com/anishathalye/neural-style) seems to satisfy our criteria, let’s focus on it. Take 5 minutes to read and run the GitHub repository on its inherent data. You should see the message “Iteration .../1000”. What challenges did you encounter?** 
 
  * **It seems that a few minutes is not enough to reproduce good results locally. What can you tweak to overcome this challenge?**

  * **Run the codebase on your own chosen images for content and style. Use 100 iterations.**

This section was designed to help you get started with the existing code bases related to your project. Note that we only tested the model here, and did not train it. For your project, find a GitHub repository that is relevant to your project and try to reproduce the results.


# Tips for Building Your Own Baseline Model

If your task hasn’t been tackled before, you can start by building a simple algorithm that solves the problem without aiming for high accuracy. 

You will often notice that your newly created neural network struggles and isn’t very accurate. A good first step is to try to overfit on a very small number of examples, and then gradually add more and more. By focusing on a few examples, you can run many variations of your architecture and hyperparameters in a short amount of time. When your model starts overfitting on a good amount of training examples, you can then analyze the its generalization capabilities on unseen data. In C2M1 and C2M2, you will learn about the techniques used to help your model generalize to the real world.


# Cloud Computing - Setting Up an AWS Instance 
 
Training a deep learning model often requires a lot of computational power - that’s why we use specialized hardware, such as GPUs or TPUs. These processors can speed up training by many orders of magnitude.
 
Cloud computing services such as Amazon Web Services (AWS), Google Cloud, and Microsoft Azure allow us to access powerful computer instances on-demand: we can have just the right amount of power, right when we need it! AI practitioners should know how to work with these remote computers in order to access the right hardware.
 
Next, we’ll walk through how to set up your own AWS instance.
 
 
## Setting up an AWS Instance
 
There are different types of AWS instances. We will use the p2.xlarge for accelerated computing, which contains one NVIDIA K80 GPU.
 
- Create an account [here](https://portal.aws.amazon.com/billing/signup?nc2=h_ct&src=default&redirect_url=https%3A%2F%2Faws.amazon.com%2Fregistration-confirmation#/start).
- Sign in into your account [here](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fstate%3DhashArgs%2523%26isauthcode%3Dtrue&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fhomepage&forceMobileApp=0).
- In the top right corner of the home page, click on the location name and set it to US West (Oregon). This AWS region has instances with GPUs, and is close by to most of us. 
{% include image.html description="" link="" image="section/7/region.png" caption="false"%}
- After selecting the region, click on EC2 under the Compute list.
{% include image.html description="" link="" image="section/7/compute.png" caption="false"%}
- In order to create a GPU instance, we’ll need to request a limit increase [here](https://console.aws.amazon.com/support/cases#/create?issueType=service-limit-increase&limitType=ec2-instances). Choose Region as US West (Oregon), Instance Type as p2.xlarge, and New limit value as 1. For use case, you can write something like “Training neural networks for the Stanford deep learning class”. AWS will contact you when your increase is approved: then, continue with the following steps.
- On the EC2 Dashboard view, click on the “Launch Instance” button.
- Search for and select the **Deep Learning AMI (Ubuntu)**. This AMI (Amazon Machine Image) comes with pre-installed deep learning frameworks such as TensorFlow, PyTorch or Keras.
- In the next page, select the p2.xlarge instance. Then, click on “Review and Launch”.
{% include image.html description="" link="" image="section/7/review.png" caption="false"%}
- Then, click on the blue button “Launch”.
- A pop-up window will appear asking for a key pair. You can either provide one or create one. If you create one, you should download it and keep it somewhere it won’t be deleted (if that happens, you won’t be able to access your instance anymore!).
- If you downloaded the key file, change its permissions in the terminal to user-only read and write. In Linux, this could be done with `chmod 600 PEM_FILENAME` where PEM_FILENAME is the file with the key.
- After this, click on the blue button “Launch Instances”. 
- Click on “View Instances” to check that it is “Running” and passed “2/2 status checks”. It will take some time to pass the checks but after that, you will be ready to ssh into the instance. Finally, note down the Public IP of the instance launched (it will be required in the next step).
- SSH in your instance with `ssh -i PEM_FILENAME ubuntu@PUBLIC_IP`.
- Your machine comes with many Conda environments pre-installed: each one is a Python environment with deep learning libraries already installed. Look at the README for how to use them. For this section, we can use a Tensorflow environment (`conda activate tensorflow_p36`).
- **Important!** When you’re done using your instance, be sure to turn it off using the web interface!
 
 
Now, let’s use this AWS instance to run our neural style transfer code. It now runs extremely quickly with 1000 iterations!
 
# Additional AWS Info

- We'll be distributing AWS credits to all project groups. Stay tuned for announcements on Piazza.
- AWS bills instances by the minute, so make sure to turn off your machine (and save your data, if needed!) when you're done using it.
- For those training large networks, the p3.2xlarge can be used, with one NVIDIA V100 GPU. This instance can train networks much faster, but is also 3x more expensive.
 
# Further Reading

If you’re interested learning more about style transfer, here are some of the most important papers on the topic. We'll also be talking about style transfer in class, so stay tuned!
 * [A Neural Algorithm of Artistic Style](https://arxiv.org/pdf/1508.06576.pdf), Gatys et al. (2015) 
 * [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/pdf/1603.08155.pdf), Johnson et al. (2016)
 * [A learned representation for artistic style](https://arxiv.org/pdf/1610.07629.pdf), Dumoulin et al. (2016)
 * [Demystifying Neural Style Transfer](https://arxiv.org/abs/1701.01036), Li et al. (2017)
 * [Exploring the structure of a real-time, arbitrary neural artistic stylization network](https://arxiv.org/pdf/1705.06830.pdf), Ghiasi et al. (2017)
 * [Neural Artistic Style: a Comprehensive Look](https://medium.com/artists-and-machine-intelligence/neural-artistic-style-transfer-a-comprehensive-look-f54d8649c199), Desai (2017)

