---
# Page settings
layout: default
keywords:
comments: false
 
# Hero section
title: Section 1
description: The goal of this section is to give you insights on how to build a successful CS 230 project. 
 
# Micro navigation
micro_nav: true
 
---
 
 
# Getting Started with Your Project
 
### What is the CS 230 Project?
 
CS230's main goal is to prepare you to apply deep learning algorithms to real-world tasks, and leave you well-qualified to start deep learning and AI research. The final project jumpstarts you in these directions, and is the main focus of the class.
 
Your project will be done in groups of 1 to 3 students (4 with TA approval), and has the following steps:
 
  - [Proposal](/project/#proposal) (Due 04/16)
  - [Milestone](/project/#milestone) (Due 05/14)
  - [Poster](/project/#poster) (Due 06/09)
  - [Final Report](/project/#final-report) (Due 06/09)
 
To help guide your project, TAs will host project office hours (15 mins per group, per week) with mandatory meetings for the first meeting, week after the proposal, week after the milestone, and week before the final submission.
 
The CS230 project can be combined with other classes’ final projects, but must be deep learning focused.
 
### Types of Projects
 
Historically, students who have built successful CS230 projects have done one of the following:
 
 * **Used popular network architectures to perform a novel task.** Students have used the YOLO algorithm to detect humans on drone footage. They then cropped the humans out of the pictures and filled in the humans’ positions with generated background using a Generative Adversarial Network. Students have also fine-tuned existing networks to achieve state-of-the-art accuracy in Tree Species Identification.
 * **Came up with custom neural network architectures to perform an existing (or novel) task.** Students made changes to the U-Net neural network to improve performance on tasks such as brain tumor segmentation. Students have also improved task accuracy by adding and training an attention mechanism on top of an existing RNN architecture.
 * **Re-implemented a famous research paper.** For instance, students have reimplemented the popular WaveNet algorithm from scratch.
 * **Done a research project.** A past group designed a neural network to debias word vectors using a novel algorithm. They then submitted their paper to a conference.
 
 Note that the common denominator of these projects is that students have contributed something *novel*. Of course, the above categories are not the only ones. You’re encouraged to talk with your project mentor to figure out if your project idea is aligned with CS230 expectations.
 
 
# Steps to Build a Deep Learning Project 
 
## **Step 1: Choose a Project Idea**
 
 * Look at [past projects](/past-projects) from CS230 and other Stanford machine learning classes ([CS229](http://cs229.stanford.edu/), [CS229A](https://web.stanford.edu/class/cs229a/), [CS221](http://web.stanford.edu/class/cs221/), [CS224N](http://web.stanford.edu/class/cs224n/), [CS231N](http://cs231n.stanford.edu/)).
 * Look at recent research papers in deep learning using an academic search engine such as [Google Scholar](http://scholar.google.com), searching through main machine learning conferences such as [ICML](https://icml.cc/) and [NIPS](https://nips.cc/), or going through this [blog](https://paperswithcode.com/sota).
 * Check out these great GitHub repositories: 
   - [Awesome NLP](https://github.com/keon/awesome-nlp)
   - [Awesome GAN](https://github.com/nightrome/really-awesome-gan)
   - [Awesome DL](https://github.com/endymecy/awesome-deeplearning-resources/blob/master/papers/2018/dl.md)
 
## **Step 2: Literature Review**
 
Find related research papers and Github repositories (We’ll look at this in section 2!).
 
## **Step 3: Find a Dataset**
 
**Building a dataset**
 
 * Use a web scraping library such as [MechanicalSoup](https://mechanicalsoup.readthedocs.io/en/stable/).
 * Generate synthetic data from a model currently being used in your research.
 * Collect data yourself (Kian once spent two days on campus collecting short recordings of students saying "activate" to build a speech recognition algorithm).
 
 
The focus of CS230's project is on developing deep learning models.  Finding the right application and dataset is very important, but it is only the first piece in the puzzle.  **Don't spend too much time on data collection.**  In order to maximize your time spent on developing models, it might be a good idea to look at well defined tasks and datasets. 
 
**Use a pre-existing dataset**
 
 * Use Google's [Dataset Search](https://toolbox.google.com/datasetsearch) tool.
 * Look through Kaggle's [datasets](https://www.kaggle.com/datasets) and [competitions](https://www.kaggle.com/competitions) (current and past).
 * Use a dataset from your own research.
 * Use a standard benchmarked dataset for a specific task.
 
#### Computer Vision 
 
{% include image.html description="Examples of computer vision tasks" link="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" image="section/1/vision.png" caption="true"%}
 
* Image Classification 
  - [Imagenet](http://www.image-net.org/): 14M images and more than 20k classes.
  - [MNIST](http://yann.lecun.com/exdb/mnist/): Dataset of handwritten digits with 10 classes. 70k low resolution images (50Mb)
  - [CIFAR 10/100](https://www.cs.toronto.edu/~kriz/cifar.html): Dataset with 60k low resolution images (10 and 100 classes respectively)
* Object Detection
  - [COCO](http://cocodataset.org/#home): Dataset for object detection, image segmentation and image captioning. It has more than 200k images with 80 object categories.
  - [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/): Dataset of 20k images labelled with bounding boxes and 20 classes.
  - [Open Images](https://storage.googleapis.com/openimages/web/index.html): 9M images that have been annotated with image-level labels and object bounding boxes.
 
 
#### Sequence Models
 
{% include image.html description="Examples of NLP and speech applications" link="https://www.coursera.org/learn/nlp-sequence-models" image="section/1/nlp.png" caption="true"%}
 
* Natural Language Processing
  - [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/): The Stanford Question Answering Dataset
  - [Google Books n-grams](https://books.google.com/ngrams)
  - [Yelp Open Dataset](https://www.yelp.com/dataset): A subset of Yelp's businesses, reviews, and user data.
* Time Series
  - Yahoo Finance API
* Video Classification
  - [Youtube-8M](https://research.google.com/youtube8m/)
  - [Moments in Time](http://moments.csail.mit.edu/)
  - [Kinetics-600](https://deepmind.com/research/open-source/open-source-datasets/kinetics/)
* Music
  - [Million Song](https://labrosa.ee.columbia.edu/millionsong/): A collection of audio features and metadata for a million contemporary popular music tracks.
* Computational Biology
  - [Deep Bind](http://tools.genes.toronto.edu/deepbind/)
 
 
#### Miscellaneous
 
{% include image.html description="Results of the image-to-image translation model CycleGAN Zhu, Park et al." link="https://github.com/junyanz/CycleGAN" image="section/1/gan.gif" caption="true"%}
 
 * Generative Adversarial Networks
   - [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html): a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations.
 * Recommendation Systems and Autoencoders
   - [MovieLens](https://grouplens.org/datasets/movielens/): 20 million ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users. 
   - [Netflix Prize Challenge](https://www.netflixprize.com/index.html):
 * Adversarial Attack and Defense
   - [CleverHans](https://github.com/tensorflow/cleverhans): A Python library to benchmark machine learning systems' vulnerability to adversarial examples.
 * Deep Reinforcement Learning
   - [OpenAI Gym](https://gym.openai.com/): A toolkit for developing and comparing reinforcement learning algorithms.
 * Style Transfer
 
### **Questions to ask when choosing a dataset**
 
**How much data do I need?** 
 
In general, the more data the better: tens of thousands is a good number for many tasks.
 
Here's some more intuition. The amount of data required depends on:
 
- Complexity of the task (output, number of features...). For instance, the amount of data needed generally increases with the number of classes in classification.
  * Binary classification cat/non cat (simplest) 
  * 10 classes classification (more complex)
  * Image classification for ImageNet: 14 million images, more than 20k classes (most complex)
- Complexity of the model (number of parameters): shallow / deep neural network.
- Reference papers related to your algorithm and specific application (ex. Generative Adversarial Networks)
 
**How diverse and balanced is the dataset?**
 
For instance, for classification, we may want to collect more data for the class which has more errors (to help the network better understand that class). 
 
**What if there isn't enough data?**
 
- Find or collect more data (or use a different dataset)
- Try data augmentation techniques
- Transfer learning 
 
**How clean is the dataset?**
 
Ideally, you’re working with a dataset that requires minor cleaning and preprocessing, so that you can focus on the neural networks. However, if you need to spend significant time preparing the data, we will take it into account when evaluating your project!
 
**Is the dataset academic, licensed, or proprietary?**
 
- Academic datasets are great for academic, non-commercial use
- If you're working with healthcare data, keep in mind privacy and legal concerns 
- Dataset licenses: CC, CC BY, CC BY-NC (non-commercial use)
- For source code, open source licenses include: MIT, Apache, GNU GPL
 
## **Step 4: Choose an appropriate evaluation metric and build your first model**
 
## **Step 5: Iterate on your model and evaluation to improve your results**
 
We'll talk more about these last two steps later in the course and sections!
 
 
# Q&A
 
As you progress on your project, your project mentor will answer your specific questions and help guide you towards a successful project. Have fun getting started, we’re excited to see what you come up with!
 
